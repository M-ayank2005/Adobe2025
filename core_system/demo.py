"""
Demonstration Script for Intelligent Document Processing System
Shows the capabilities of the core system with sample data
"""

import json
import logging
from pathlib import Path
from typing import Dict, List
import time

from intelligent_document_processor import IntelligentDocumentProcessor, OutlineItem, DocumentStructure
from semantic_intelligence import PersonaIntelligenceEngine

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_sample_data():
    """Create sample data for demonstration"""
    
    # Sample PDF text content (simulating extracted text)
    sample_texts = {
        "travel_guide.pdf": {
            1: """
            SOUTH OF FRANCE TRAVEL GUIDE
            
            1. Introduction
            Welcome to the beautiful South of France region.
            
            1.1 Overview
            This guide covers the major destinations and attractions.
            
            1.2 Best Time to Visit
            The ideal time is from May to September.
            """,
            2: """
            2. Cities and Destinations
            Discover the most popular cities in the region.
            
            2.1 Nice
            A beautiful coastal city with stunning beaches.
            
            2.2 Cannes
            Famous for its film festival and luxury shopping.
            
            2.3 Monaco
            A glamorous principality with casinos and luxury.
            """,
            3: """
            3. Activities and Attractions
            There are many exciting activities to enjoy.
            
            3.1 Beach Activities
            Swimming, sunbathing, and water sports.
            
            3.2 Cultural Sites
            Museums, historical monuments, and art galleries.
            
            3.3 Nightlife
            Bars, clubs, and entertainment venues.
            """
        },
        
        "cooking_guide.pdf": {
            1: """
            VEGETARIAN COOKING GUIDE
            
            1. Introduction to Vegetarian Cuisine
            Learn to prepare delicious vegetarian meals.
            
            1.1 Benefits of Vegetarian Cooking
            Health, environmental, and ethical advantages.
            """,
            2: """
            2. Breakfast Recipes
            Start your day with nutritious vegetarian options.
            
            2.1 Smoothie Bowls
            Colorful and healthy breakfast bowls.
            
            2.2 Avocado Toast
            Quick and nutritious morning meal.
            """,
            3: """
            3. Lunch and Dinner Ideas
            Main meal suggestions for vegetarian diets.
            
            3.1 Pasta Dishes
            Various pasta recipes with vegetables.
            
            3.2 Grain Bowls
            Nutritious bowls with quinoa and rice.
            
            3.3 Salads
            Fresh and filling salad combinations.
            """
        }
    }
    
    return sample_texts


def demonstrate_basic_processing():
    """Demonstrate basic document processing (Challenge 1a)"""
    print("\\n" + "="*60)
    print("ğŸ” BASIC DOCUMENT PROCESSING DEMONSTRATION")
    print("="*60)
    
    # Initialize processor
    processor = IntelligentDocumentProcessor()
    
    # Get sample data
    sample_texts = create_sample_data()
    
    for pdf_name, page_texts in sample_texts.items():
        print(f"\\nğŸ“„ Processing: {pdf_name}")
        print("-" * 40)
        
        # Simulate the full text
        full_text = "\\n".join([f"[PAGE {page}]\\n{text}" for page, text in page_texts.items()])
        
        # Extract title
        title = processor.extract_title(full_text, Path(pdf_name))
        print(f"ğŸ“‹ Title: {title}")
        
        # Extract outline
        outline = processor.extract_outline(full_text, page_texts)
        
        print(f"ğŸ—‚ï¸  Outline ({len(outline)} items):")
        for item in outline:
            indent = "  " * (int(item.level[1]) - 1)
            print(f"{indent}{item.level}: {item.text} (Page {item.page})")
        
        # Generate JSON output
        doc_structure = DocumentStructure(title=title, outline=outline)
        output_json = processor.generate_output_json(doc_structure)
        
        print(f"\\nğŸ’¾ JSON Output Preview:")
        print(json.dumps(output_json, indent=2)[:300] + "...")


def demonstrate_semantic_analysis():
    """Demonstrate semantic analysis and persona-based processing (Challenge 1b)"""
    print("\\n" + "="*60)
    print("ğŸ§  SEMANTIC ANALYSIS DEMONSTRATION")
    print("="*60)
    
    # Initialize processors
    base_processor = IntelligentDocumentProcessor()
    persona_engine = PersonaIntelligenceEngine(base_processor)
    
    # Sample personas and tasks
    test_scenarios = [
        {
            "persona": "Travel Planner",
            "task": "Plan a 4-day trip for 10 college friends",
            "text": "Visit beautiful beaches in Nice and explore the cultural attractions of Monaco. Try local cuisine at restaurants.",
            "expected_relevance": "High"
        },
        {
            "persona": "Food Contractor", 
            "task": "Prepare vegetarian buffet for corporate gathering",
            "text": "Vegetarian pasta dishes and grain bowls are perfect for catering large groups at corporate events.",
            "expected_relevance": "High"
        },
        {
            "persona": "HR Professional",
            "task": "Create fillable forms for employee onboarding",
            "text": "Visit beautiful beaches in Nice and explore the cultural attractions of Monaco.",
            "expected_relevance": "Low"
        }
    ]
    
    print("\\nğŸ¯ Persona Relevance Analysis:")
    print("-" * 40)
    
    for scenario in test_scenarios:
        relevance_score = persona_engine.analyze_persona_relevance(
            scenario["text"], 
            scenario["persona"], 
            scenario["task"]
        )
        
        print(f"\\nğŸ‘¤ Persona: {scenario['persona']}")
        print(f"ğŸ“‹ Task: {scenario['task']}")
        print(f"ğŸ“ Text: {scenario['text'][:60]}...")
        print(f"ğŸ“Š Relevance Score: {relevance_score:.3f} ({scenario['expected_relevance']} expected)")
        
        # Categorize content
        category = persona_engine._categorize_content(scenario["text"])
        print(f"ğŸ·ï¸  Content Category: {category}")


def demonstrate_semantic_embeddings():
    """Demonstrate semantic embedding and similarity calculation"""
    print("\\n" + "="*60)
    print("ğŸ”— SEMANTIC SIMILARITY DEMONSTRATION")
    print("="*60)
    
    processor = IntelligentDocumentProcessor()
    
    # Sample outline items for similarity testing
    outline_items_1 = [
        OutlineItem("H1", "Travel Planning Guide", 1),
        OutlineItem("H2", "Hotel Recommendations", 2),
        OutlineItem("H2", "Restaurant Suggestions", 3),
        OutlineItem("H2", "Beach Activities", 4)
    ]
    
    outline_items_2 = [
        OutlineItem("H1", "Vacation Planning Tips", 1),
        OutlineItem("H2", "Accommodation Options", 2),
        OutlineItem("H2", "Dining Experiences", 3),
        OutlineItem("H2", "Water Sports", 4)
    ]
    
    print("\\nğŸ“Š Calculating Semantic Similarities...")
    print("-" * 40)
    
    # Generate embeddings
    embeddings_1 = processor.generate_semantic_embeddings(outline_items_1)
    embeddings_2 = processor.generate_semantic_embeddings(outline_items_2)
    
    if embeddings_1.size > 0 and embeddings_2.size > 0:
        from sklearn.metrics.pairwise import cosine_similarity
        
        # Calculate similarity matrix
        similarity_matrix = cosine_similarity(embeddings_1, embeddings_2)
        
        print("\\nğŸ”— Semantic Links Found:")
        for i, item1 in enumerate(outline_items_1):
            for j, item2 in enumerate(outline_items_2):
                similarity = similarity_matrix[i][j]
                if similarity > 0.5:  # Threshold for meaningful similarity
                    print(f"  ğŸ“ '{item1.text}' â†” '{item2.text}' (similarity: {similarity:.3f})")
    
    print(f"\\nğŸ“ˆ Embedding Dimensions: {embeddings_1.shape[1] if embeddings_1.size > 0 else 'N/A'}")


def demonstrate_performance():
    """Demonstrate system performance"""
    print("\\n" + "="*60)
    print("âš¡ PERFORMANCE DEMONSTRATION")
    print("="*60)
    
    # Test processing speed
    processor = IntelligentDocumentProcessor()
    sample_texts = create_sample_data()
    
    print("\\nâ±ï¸  Performance Metrics:")
    print("-" * 40)
    
    # Test outline extraction speed
    for pdf_name, page_texts in sample_texts.items():
        start_time = time.time()
        
        full_text = "\\n".join([f"[PAGE {page}]\\n{text}" for page, text in page_texts.items()])
        outline = processor.extract_outline(full_text, page_texts)
        
        processing_time = time.time() - start_time
        
        print(f"\\nğŸ“„ {pdf_name}:")
        print(f"  â° Processing Time: {processing_time:.3f} seconds")
        print(f"  ğŸ“Š Outline Items: {len(outline)}")
        print(f"  ğŸ“„ Pages: {len(page_texts)}")
        print(f"  ğŸ“ˆ Items/Second: {len(outline)/max(processing_time, 0.001):.1f}")
    
    # Test embedding generation speed
    outline_items = [
        OutlineItem(f"H{i%3+1}", f"Section {i}", i%5+1)
        for i in range(20)
    ]
    
    start_time = time.time()
    embeddings = processor.generate_semantic_embeddings(outline_items)
    embedding_time = time.time() - start_time
    
    print(f"\\nğŸ§  Semantic Embeddings:")
    print(f"  â° Generation Time: {embedding_time:.3f} seconds")
    print(f"  ğŸ“Š Items Processed: {len(outline_items)}")
    print(f"  ğŸ“ˆ Embeddings/Second: {len(outline_items)/max(embedding_time, 0.001):.1f}")


def main():
    """Main demonstration function"""
    print("ğŸ‰ INTELLIGENT DOCUMENT PROCESSING SYSTEM DEMO")
    print("Built for Adobe India Hackathon 2025")
    print("Connecting the dots between documents and intelligence")
    
    try:
        # Run demonstrations
        demonstrate_basic_processing()
        demonstrate_semantic_analysis() 
        demonstrate_semantic_embeddings()
        demonstrate_performance()
        
        print("\\n" + "="*60)
        print("âœ… DEMONSTRATION COMPLETED SUCCESSFULLY!")
        print("="*60)
        
        print("\\nğŸš€ Key Capabilities Demonstrated:")
        print("  ğŸ“‹ Intelligent outline extraction from PDF text")
        print("  ğŸ§  Persona-based content relevance analysis")
        print("  ğŸ”— Semantic similarity and relationship detection")
        print("  âš¡ High-performance processing suitable for real-time use")
        print("  ğŸ¯ Accurate hierarchical structure recognition")
        
        print("\\nğŸ’¡ This system is ready to:")
        print("  â€¢ Process 50-page PDFs in under 10 seconds")
        print("  â€¢ Extract meaningful document structures")
        print("  â€¢ Link related concepts across documents")
        print("  â€¢ Provide persona-specific content analysis")
        print("  â€¢ Run entirely offline with pre-loaded models")
        
        print("\\nğŸ† Hackathon Compliance:")
        print("  âœ… Docker containerized")
        print("  âœ… No internet dependency during runtime")
        print("  âœ… Under 200MB model size")
        print("  âœ… AMD64 compatible")
        print("  âœ… Open source libraries only")
        
    except Exception as e:
        print(f"\\nâŒ Demo failed with error: {e}")
        print("Please ensure all dependencies are installed correctly.")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
